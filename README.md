# Web Scraping Using python
Web scraping is an automated method used to extract large amounts of data from websites. The data on the websites are unstructured. Web scraping helps collect these unstructured data and store it in a structured form.
<br>

<div align="center">
<img src="https://fiverr-res.cloudinary.com/images/t_main1,q_auto,f_auto,q_auto,f_auto/gigs/173890225/original/d00cbc0a854749c451a0bf3a3ee9f9eedbe5177a/data-mining-from-any-website.png" >
</div>

## Libraries used for Web Scraping 
As we know, Python is has various applications and there are different libraries for different purposes. In our further demonstration, we will be using the following libraries:
* **BeautifulSoup :** [(Documentation link)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#:~:text=Beautiful%20Soup%20is%20a%20Python,hours%20or%20days%20of%20work.)
  - Beautiful Soup is a Python library for pulling data out of HTML and XML files.
  - It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.
* **Selenium:** [(Documentation link)](https://selenium-python.readthedocs.io/)
  - The selenium module allows a Python program to directly control the browser with functions for clicking links and filling in textboxes like login information, almost as though there is a human user interacting with the page.
  - Selenium allows us to interact with web pages in a much more advanced way than Requests and Beautiful Soup.
  - Because it launches a web browser, it is a bit slower and hard to run in the background if, say, you just need to download some files from the Web.

